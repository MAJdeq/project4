{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3b1bf-93c9-46f6-b6a9-a7e44d8e1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def knearestneighbors(df, k, attributes):\n",
    "\n",
    "    # Select features and target\n",
    "    X = df[attributes].values\n",
    "    y = df['disease'].values\n",
    "    \n",
    "    # Initialize Nearest Neighbors model\n",
    "    nn = NearestNeighbors(n_neighbors=k, metric='euclidean', algorithm='auto')\n",
    "\n",
    "    # Track precision, recall, and F1 scores for 10 iterations\n",
    "    test_sizes = [0.1, 0.15, 0.2, 0.25, 0.3, 0.33, 0.4, 0.45, 0.2, 0.25]\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for _ in range(10):  # 10 iterations\n",
    "        # Randomly choose a test size and perform train-test split\n",
    "        test_size = random.choice(test_sizes)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        # Fit the Nearest Neighbors model on the training set\n",
    "        nn.fit(X_train)\n",
    "\n",
    "        # Store predictions for the test set\n",
    "        y_pred = []\n",
    "        for test_point in X_test:\n",
    "            distances, indices = nn.kneighbors([test_point])\n",
    "            nbrs = df.iloc[indices[0]]\n",
    "\n",
    "            # Get the majority class among the k-nearest neighbors\n",
    "            healthy = nbrs[nbrs['disease'] == 0].count().disease\n",
    "            sick = nbrs[nbrs['disease'] == 1].count().disease\n",
    "            predict = 0 if (healthy > sick) else 1\n",
    "            y_pred.append(predict)\n",
    "\n",
    "        # Evaluate the predictions: precision, recall, F1 score\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "\n",
    "    for i, precision in enumerate(precision_scores):\n",
    "        print(f\"Iteration: {i + 1}\")  # Start iteration count from 1 instead of 0\n",
    "        print(f\"Precision Score: {precision_scores[i]}\")\n",
    "        print(f\"Recall Score: {recall_scores[i]}\")\n",
    "        print(f\"F1 Score: {f1_scores[i]}\")\n",
    "        print()\n",
    "    print(\"Mean F1 Score:\", sum(f1_scores) / len(f1_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fcd5de",
   "metadata": {},
   "source": [
    "## Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we determined (through manual testing) that the best attributes to use for our predictions are age, trestbps (resting blood pressure), chol (serum cholestoral), and thalach (maximum heart rate). We made sure to standardize these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleveland.csv')\n",
    "df = df.rename({'num': 'disease'}, axis=1)\n",
    "df['disease'] = df['disease'].apply(lambda x: min(x, 1))\n",
    "columns_to_standardize = ['age', 'trestbps', 'chol', 'thalach']\n",
    "scaler = StandardScaler()\n",
    "df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c259e2a",
   "metadata": {},
   "source": [
    "Next, we can determine the optimal value of k for this dataset. We did this using the elbow method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8832269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(k, input_df, attributes):\n",
    "  # Use knn on age. First create a nearest neighbors object.\n",
    "  nn = NearestNeighbors(n_neighbors=k, metric='euclidean', algorithm='auto')\n",
    "\n",
    "  # This builds an index data structure under the hood for query performance\n",
    "  X = input_df[attributes].values\n",
    "  fit = nn.fit(X)\n",
    "\n",
    "  # Get random patients to test on\n",
    "  n = 50\n",
    "  patients = input_df.sample(n)\n",
    "  patientsX = patients[attributes].values\n",
    "  patientsy = patients[['disease']].values\n",
    "  # display(patients)\n",
    "\n",
    "  # Find the k nearest neighbors to the patient.\n",
    "  distances, indices = fit.kneighbors(patientsX)\n",
    "\n",
    "  y_pred = []\n",
    "  for i in range(n):\n",
    "      nbrs = input_df.iloc[indices[i]]\n",
    "      # Drop the patient of interest\n",
    "      nbrs = nbrs.drop(patients.index[i], errors='ignore')\n",
    "\n",
    "      healthy = nbrs[nbrs.disease == 0].count().disease\n",
    "      sick = nbrs[nbrs.disease == 1].count().disease\n",
    "      predict = 0 if (healthy > sick) else 1\n",
    "      y_pred.append(predict)\n",
    "\n",
    "  return precision_recall_fscore_support(patientsy, y_pred, labels=[1])\n",
    "\n",
    "def determine_k(input_df, attributes):\n",
    "\n",
    "  kvals = range(2, 250)\n",
    "  scores = [get_scores(k, input_df, attributes) for k in kvals]\n",
    "  scores = [(p[0], r[0], f[0], s[0]) for (p,r,f,s) in scores]\n",
    "  scores = list(zip(*scores))\n",
    "\n",
    "  k_options = pd.DataFrame(\n",
    "    {'f score': scores[2],\n",
    "     'k': kvals\n",
    "    })\n",
    "\n",
    "  k_options = k_options.sort_values(by='f score', ascending=False)\n",
    "\n",
    "  return (kvals, scores[2], k_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590339d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = determine_k(df, ['age', 'trestbps', 'chol', 'thalach'])\n",
    "result[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result[0], result[1])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('f score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d143111",
   "metadata": {},
   "source": [
    "Now that we've determined the optimal k and set of attributes, we can use the k nearest neighbors method to predict whether patients have heart disease. We'll also evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a26423",
   "metadata": {},
   "outputs": [],
   "source": [
    "knearestneighbors(df, 10, ['age', 'trestbps', 'chol', 'thalach'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5decec44",
   "metadata": {},
   "source": [
    "## Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd646cc",
   "metadata": {},
   "source": [
    "Now, we will repeat the same process for our second data set. This data set contains information about urls and whether they are known to be phishing or legitimate. \n",
    "\n",
    "Source: https://archive.ics.uci.edu/dataset/967/phiusiil+phishing+url+dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
